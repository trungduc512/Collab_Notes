const { Kafka } = require("kafkajs");
const { MongodbPersistence } = require("y-mongodb-provider");
const Y = require("yjs"); // C·∫ßn Yjs ƒë·ªÉ x·ª≠ l√Ω logic update n·∫øu c·∫ßn

const KAFKA_BROKER = process.env.KAFKA_BROKER || "kafka:29092";
const MONGO_URI =
  process.env.MONGODB_URI || "mongodb://mongo:27017/collab_notes";
const TOPIC_NAME = "yjs-updates"; // Topic ch·ª©a binary update
const GROUP_ID = "yjs-storage-worker";

// === SETUP MONGODB PERSISTENCE ===
const mdb = new MongodbPersistence(MONGO_URI, {
  collectionName: "yjs-transactions",
  flushSize: 100, // V·∫´n t·∫≠n d·ª•ng kh·∫£ nƒÉng batching c·ªßa th∆∞ vi·ªán n√†y
});

// === SETUP KAFKA ===
const kafka = new Kafka({
  clientId: "storage-worker",
  brokers: [KAFKA_BROKER],
});
const consumer = kafka.consumer({ groupId: GROUP_ID });

const run = async () => {
  await consumer.connect();
  await consumer.subscribe({ topic: TOPIC_NAME, fromBeginning: false });

  console.log("‚úÖ Worker is ready to write updates to MongoDB");

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const docName = message.key.toString();
      const updateBuffer = message.value; // ƒê√¢y l√† Buffer

      // Chuy·ªÉn Buffer v·ªÅ Uint8Array m√† Yjs hi·ªÉu
      const update = new Uint8Array(updateBuffer);

      console.log(
        `üíæ Persisting update for doc: ${docName} (Size: ${update.length})`
      );

      try {
        // === GHI XU·ªêNG MONGO ===
        // H√†m storeUpdate c·ªßa th∆∞ vi·ªán y-mongodb-provider s·∫Ω l∆∞u c√°i update nh·ªè n√†y v√†o DB
        await mdb.storeUpdate(docName, update);
        console.log(`‚úÖ Update for doc '${docName}' written to MongoDB`);
      } catch (err) {
        console.error(`‚ùå Error writing to Mongo:`, err);
      }
    },
  });
};

run();
